{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Work № 5: Predicting the risk of heart disease in patients\n",
    "## Authors:\n",
    "|Name|Surname|Student ID|E-mail|\n",
    "|---|---|---|---|\n",
    "|Kamal|Ahmadov|22022692|kamal.ahmadov1@ufaz.az|   \n",
    "|Murad|Mustafayev|22022733 |murad.mustafayev@ufaz.az|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Objective & Dataset\n",
    "Within the framework of this practical work, we have to train models on the “Cleveland Heart Disease” dataset in order to **predict the risk of heart disease in patients**. This dataset contains 303 instances and each instance is described by 14 attributes. Each of these attributes are phylosiological measurements. Let's first load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_data = pd.read_csv('heart.csv')\n",
    "heart_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's overview the dataset and its attributes:\n",
    "\n",
    "|Attribute|Description|\n",
    "|---|---|\n",
    "|age|The person’s age in years|  \n",
    "|sex|The person’s sex (1 = male, 0 = female)|\n",
    "|chest pain type| The chest pain experienced (Value 1 : typical angina, Value 2 : atypical angina, Value 3 : non-anginal pain, Value 4 : asymptomatic)\n",
    "|resting blood pressure|The person’s resting blood pressure (mm Hg on admission to the hospital)|\n",
    "|cholesterol|The person’s cholesterol measurement in mg/dl|\n",
    "|fasting blood sugar|The person’s fasting blood sugar (> 120 mg/dl, 1 = true ; 0 = false)|\n",
    "|rest ecg|Resting electrocardiographic measurement (0 = normal, 1 = having ST-T wave abnormality, 2 = showing probable or definite left ventricular hypertrophy by Estes’ criteria)\n",
    "|max hear rate achieved|The person’s maximum heart rate achieved|\n",
    "|exercise induced angina|Exercise induced angina (1 = yes; 0 = no)|\n",
    "|st depression|ST depression induced by exercise relative to rest (‘ST’ relates to positions on the ECG plot|\n",
    "|st slope| the slope of the peak exercise ST segment (Value 1 : upsloping, Value 2 : flat, Value 3 : downsloping)|\n",
    "|num major blood vessels| The number of major vessels (0-3)|\n",
    "|thalassemia|A blood disorder called thalassemia (3 = normal ; 6 = fixed defect ; 7 = reversable defect)|\n",
    "|target|Diagnosis of a heart disease (0 = no, 1 = yes)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions related to the table above:\n",
    "1. What is the name of the attribute we want to predict?<br>**Answer:** The attribute we want to predict is named \"target,\" which represents the diagnosis of heart disease (0 = no, 1 = yes).\n",
    "2. Is that a binary or a multi-class classification?<br>**Answer:** It is a binary classification problem since the target variable has two classes: 0 (no heart disease) and 1 (heart disease).\n",
    "3. What are the types of the attributes?<br>**Answer:** The types of the attributes are both numerical and categorical.The categorical attributes in the dataset are:\n",
    "- Sex\n",
    "- Chest pain type\n",
    "- Fasting blood sugar\n",
    "- Rest ECG\n",
    "- Exercise induced angina\n",
    "- ST slope\n",
    "- Thalassemia\n",
    "4. How can we encode categorical attributes?<br>**Answer:** Categorical attributes can be encoded using techniques such as one-hot encoding or label encoding:\n",
    "- *One-hot encoding:* This technique creates binary columns for each category and represents the presence or absence of a category with a 1 or 0, respectively.\n",
    "- *Label encoding:* This technique assigns a unique integer to each category. However, it should be noted that label encoding may not be suitable for attributes where the categories do not have an ordinal relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions on attribute normalization:\n",
    "1. Which normalization method will be best adapted so we can preserve the variance of the dataset?<br>**Answer:** The Z-score normalization function, also known as standardization, is best adapted to preserve the variance of the dataset. In Z-score normalization, each feature is scaled to have a mean of 0 and a standard deviation of 1. This method preserves the shape of the distribution and ensures that each feature has the same scale, which is important for many machine learning algorithms.\n",
    "2. Will you normalize the data before or after splitting the dataset in training/testing datasets?<br>**Answer:** It's generally recommended to normalize the data after splitting the dataset into training and testing sets. This helps prevent data leakage from the testing set into the training set, which could lead to overly optimistic evaluation metrics. Normalizing the data after splitting ensures that each set (training and testing) is normalized independently based on its own statistics.\n",
    "3. Implement a method/function to normalize the attribute using the adequate normalization method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_normalization(data):\n",
    "    \"\"\"\n",
    "    Normalize the attributes using Z-score normalization (standardization).\n",
    "\n",
    "    Parameters:\n",
    "    data (pandas.DataFrame): Input data with columns representing attributes.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: Normalized data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # X_normalized = (X - X.mean(axis=0)) / X.std(axis=0), this logic \n",
    "    \n",
    "    # calculate the mean of each column\n",
    "    mean = data.mean(axis=0)\n",
    "    \n",
    "    # calculate the standard deviation of each column\n",
    "    std = data.std(axis=0)\n",
    "    \n",
    "    # standardize the data\n",
    "    data_normalized = (data - mean) / std\n",
    "    \n",
    "    return data_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Predictions using a Multi-layer perceptron (MLP)\n",
    "As a first step, we will use MLP with 1 hidden layer containing 5 units.\n",
    "\n",
    "Questions:\n",
    "1. What are the dimensions of the matrices you will use to represent your model (inputs, parameters and outputs) ? How will you integrate the concept of mini-batch training?<br>**Answer:** For an MLP with 1 hidden layer containing 5 units, let's break down the dimensions of the matrices:\n",
    "- Inputs: The input matrix would have dimensions (`batch_size`, `input_features`), where `batch_size` represents the number of samples in each mini-batch and `input_features` represents the number of features in each sample.\n",
    "- Parameters: \n",
    "    - Weights between input layer and hidden layer: This matrix would have dimensions (`input_features`, `num_hidden_units`), where `num_hidden_units` is the number of units in the hidden layer.\n",
    "    - Biases for the hidden layer: This vector would have dimensions (`num_hidden_units`).\n",
    "    - Weights between hidden layer and output layer: This matrix would have dimensions (`num_hidden_units`, `num_classes`), where `num_classes` is the number of output classes.\n",
    "    - Biases for the output layer: This vector would have dimensions (num_classes).\n",
    "- Outputs: The output matrix would have dimensions (`batch_size`, `num_classes`), where `num_classes` is the number of output classes.\n",
    "\n",
    "To integrate mini-batch training, we'll update the parameters (weights and biases) using gradients computed on mini-batches rather than the entire dataset. We'll iterate through the dataset in mini-batches, compute gradients for each mini-batch, and update the parameters accordingly using optimization techniques like gradient descent or its variants.\n",
    "\n",
    "2. How should you check whether or not you should keep training your model?<br>**Answer:** \n",
    "We should monitor the performance of our model on a separate validation dataset. We'll keep track of metrics such as accuracy, loss, or any other relevant evaluation metric. If the performance on the validation dataset stops improving or starts to degrade, it might indicate that our model is overfitting or that further training is not beneficial. At this point, we should consider stopping the training process to prevent overfitting and save computational resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Draw your network (you can use the following online tool: `http://alexlenail.me/NN-SVG/index.html`)\n",
    "\n",
    "<div style=\"width: 100%\">\n",
    "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"750\" height=\"585\" style=\"cursor: move; touch-action: none; -webkit-tap-highlight-color: rgba(0, 0, 0, 0);\"><g transform=\"translate(-190,-158.10496907694926)\"><path class=\"link\" marker-end=\"\" d=\"M480,179C571.5,179 571.5,394 663,394\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 37, 37); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,179C571.5,179 571.5,437 663,437\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 151, 151); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,179C571.5,179 571.5,480 663,480\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(168, 168, 255); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,179C571.5,179 571.5,523 663,523\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(128, 128, 255); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,222C571.5,222 571.5,394 663,394\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(248, 248, 255); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,222C571.5,222 571.5,437 663,437\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 88, 88); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,222C571.5,222 571.5,480 663,480\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 237, 237); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,222C571.5,222 571.5,523 663,523\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 0, 0); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,265C571.5,265 571.5,394 663,394\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(47, 47, 255); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,265C571.5,265 571.5,437 663,437\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 11, 11); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,265C571.5,265 571.5,480 663,480\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(175, 175, 255); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,265C571.5,265 571.5,523 663,523\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 96, 96); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,308C571.5,308 571.5,394 663,394\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 80, 80); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,308C571.5,308 571.5,437 663,437\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 161, 161); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,308C571.5,308 571.5,480 663,480\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 104, 104); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,308C571.5,308 571.5,523 663,523\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 17, 17); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,351C571.5,351 571.5,394 663,394\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 174, 174); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,351C571.5,351 571.5,437 663,437\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(66, 66, 255); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,351C571.5,351 571.5,480 663,480\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(4, 4, 255); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,351C571.5,351 571.5,523 663,523\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 185, 185); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,394C571.5,394 571.5,394 663,394\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 192, 192); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,394C571.5,394 571.5,437 663,437\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 205, 205); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,394C571.5,394 571.5,480 663,480\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(97, 97, 255); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,394C571.5,394 571.5,523 663,523\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 241, 241); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,437C571.5,437 571.5,394 663,394\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(254, 254, 255); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,437C571.5,437 571.5,437 663,437\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 120, 120); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,437C571.5,437 571.5,480 663,480\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(49, 49, 255); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,437C571.5,437 571.5,523 663,523\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(152, 152, 255); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,480C571.5,480 571.5,394 663,394\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(39, 39, 255); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,480C571.5,480 571.5,437 663,437\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(195, 195, 255); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,480C571.5,480 571.5,480 663,480\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 129, 129); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,480C571.5,480 571.5,523 663,523\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 236, 236); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,523C571.5,523 571.5,394 663,394\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 31, 31); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,523C571.5,523 571.5,437 663,437\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(74, 74, 255); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,523C571.5,523 571.5,480 663,480\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(187, 187, 255); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,523C571.5,523 571.5,523 663,523\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 218, 218); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,566C571.5,566 571.5,394 663,394\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(210, 210, 255); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,566C571.5,566 571.5,437 663,437\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 229, 229); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,566C571.5,566 571.5,480 663,480\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 205, 205); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,566C571.5,566 571.5,523 663,523\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(40, 40, 255); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,609C571.5,609 571.5,394 663,394\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 28, 28); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,609C571.5,609 571.5,437 663,437\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 96, 96); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,609C571.5,609 571.5,480 663,480\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(40, 40, 255); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,609C571.5,609 571.5,523 663,523\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 23, 23); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,652C571.5,652 571.5,394 663,394\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 177, 177); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,652C571.5,652 571.5,437 663,437\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(254, 254, 255); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,652C571.5,652 571.5,480 663,480\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 100, 100); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,652C571.5,652 571.5,523 663,523\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 140, 140); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,695C571.5,695 571.5,394 663,394\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 234, 234); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,695C571.5,695 571.5,437 663,437\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 108, 108); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,695C571.5,695 571.5,480 663,480\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 184, 184); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M480,695C571.5,695 571.5,523 663,523\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 235, 235); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M663,351C754.5,351 754.5,437 846,437\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(255, 127, 127); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M663,394C754.5,394 754.5,437 846,437\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(11, 11, 255); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M663,437C754.5,437 754.5,437 846,437\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(105, 105, 255); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M663,480C754.5,480 754.5,437 846,437\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(18, 18, 255); fill: none;\"></path><path class=\"link\" marker-end=\"\" d=\"M663,523C754.5,523 754.5,437 846,437\" style=\"stroke-width: 0.63; stroke-opacity: 1; stroke: rgb(156, 156, 255); fill: none;\"></path><circle r=\"11.5\" class=\"node\" id=\"0_0\" cx=\"480\" cy=\"179\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"11.5\" class=\"node\" id=\"0_1\" cx=\"480\" cy=\"222\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"11.5\" class=\"node\" id=\"0_2\" cx=\"480\" cy=\"265\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"11.5\" class=\"node\" id=\"0_3\" cx=\"480\" cy=\"308\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"11.5\" class=\"node\" id=\"0_4\" cx=\"480\" cy=\"351\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"11.5\" class=\"node\" id=\"0_5\" cx=\"480\" cy=\"394\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"11.5\" class=\"node\" id=\"0_6\" cx=\"480\" cy=\"437\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"11.5\" class=\"node\" id=\"0_7\" cx=\"480\" cy=\"480\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"11.5\" class=\"node\" id=\"0_8\" cx=\"480\" cy=\"523\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"11.5\" class=\"node\" id=\"0_9\" cx=\"480\" cy=\"566\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"11.5\" class=\"node\" id=\"0_10\" cx=\"480\" cy=\"609\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"11.5\" class=\"node\" id=\"0_11\" cx=\"480\" cy=\"652\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"11.5\" class=\"node\" id=\"0_12\" cx=\"480\" cy=\"695\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"11.5\" class=\"node\" id=\"1_0\" cx=\"663\" cy=\"351\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"11.5\" class=\"node\" id=\"1_1\" cx=\"663\" cy=\"394\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"11.5\" class=\"node\" id=\"1_2\" cx=\"663\" cy=\"437\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"11.5\" class=\"node\" id=\"1_3\" cx=\"663\" cy=\"480\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"11.5\" class=\"node\" id=\"1_4\" cx=\"663\" cy=\"523\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><circle r=\"11.5\" class=\"node\" id=\"2_0\" cx=\"846\" cy=\"437\" style=\"fill: rgb(255, 255, 255); stroke: rgb(51, 51, 51);\"></circle><text class=\"text\" dy=\".35em\" x=\"445\" y=\"738\" style=\"font-size: 12px;\">Input Layer ∈ ℝ¹³</text><text class=\"text\" dy=\".35em\" x=\"628\" y=\"738\" style=\"font-size: 12px;\">Hidden Layer ∈ ℝ⁵</text><text class=\"text\" dy=\".35em\" x=\"811\" y=\"738\" style=\"font-size: 12px;\">Output Layer ∈ ℝ¹</text></g><defs><marker id=\"arrow\" viewBox=\"0 -5 10 10\" markerWidth=\"7\" markerHeight=\"7\" orient=\"auto\" refX=\"44.199999999999996\"><path d=\"M0,-5L10,0L0,5\" style=\"stroke: rgb(80, 80, 80); fill: rgb(0, 0, 0);\"></path></marker></defs></svg>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's implement the MLP model and train it on the dataset. Only numpy, pandas, and matplotlib libraries are going to be used for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of MLP Creation and Activation Function Choice\n",
    "\n",
    "In our Multi-Layer Perceptron (MLP) class, we aim to create a versatile model capable of handling binary classification tasks. Below are the steps involved in creating this class:\n",
    "\n",
    "1. **Activation Function Selection**:\n",
    "    - **Hidden Layer Activation Function**: For the hidden layer, we need an activation function that introduces non-linearity to capture complex patterns in the data. Common choices include ReLU, sigmoid, or hyperbolic tangent (tanh) functions. We've chosen the sigmoid function for its ability to squash the output to the range [0, 1], making it suitable for binary classification tasks. Additionally, sigmoid is differentiable, facilitating gradient-based optimization.\n",
    "    - **Output Layer Activation Function**: For binary classification tasks like ours, the sigmoid activation function is appropriate for the output layer. It transforms the output into a probability score between 0 and 1, which can be interpreted as the likelihood of belonging to a certain class.\n",
    "\n",
    "2. **Forward Pass**: \n",
    "    - In the forward pass, we compute the output of each layer by applying the activation function to the linear combination of inputs and weights. Mathematically, for the hidden layer:\n",
    "        - $ Z^{(1)} = X \\cdot W^{(1)} + b^{(1)} $\n",
    "        - $ A^{(1)} = \\sigma(Z^{(1)}) $\n",
    "    - Where:\n",
    "        - $ X $ is the input data.\n",
    "        - $ W^{(1)} $ is the weight matrix of the hidden layer.\n",
    "        - $ b^{(1)} $ is the bias vector of the hidden layer.\n",
    "        - $ Z^{(1)} $ is the weighted sum of inputs and weights.\n",
    "        - $ A^{(1)} $ is the output of the hidden layer after applying the sigmoid activation function.\n",
    "    - Similarly, for the output layer:\n",
    "        - $ Z^{(2)} = A^{(1)} \\cdot W^{(2)} + b^{(2)} $\n",
    "        - $ A^{(2)} = \\sigma(Z^{(2)}) $\n",
    "    - Where:\n",
    "        - $ W^{(2)} $ is the weight matrix of the output layer.\n",
    "        - $ b^{(2)} $ is the bias vector of the output layer.\n",
    "        - $ Z^{(2)} $ is the weighted sum of inputs and weights.\n",
    "        - $ A^{(2)} $ is the output of the output layer after applying the sigmoid activation function.\n",
    "\n",
    "3. **Loss Computation**: The `compute_loss` function calculates the binary cross-entropy loss, which measures the difference between the predicted probabilities and the ground truth labels.\n",
    "\n",
    "4. **Backward Pass**: \n",
    "    - In the backward pass, we compute the gradients of the loss function with respect to the weights and biases using backpropagation. Mathematically, for the output layer:\n",
    "        - $ dZ^{(2)} = A^{(2)} - y $\n",
    "        - $ dW^{(2)} = \\frac{1}{m} A^{(1)T} \\cdot dZ^{(2)} $\n",
    "        - $ db^{(2)} = \\frac{1}{m} \\sum_{i=1}^{m} dZ^{(2)} $\n",
    "    - For the hidden layer:\n",
    "        - $ dZ^{(1)} = (dZ^{(2)} \\cdot W^{(2)T}) \\cdot A^{(1)} \\cdot (1 - A^{(1)}) $\n",
    "        - $ dW^{(1)} = \\frac{1}{m} X^T \\cdot dZ^{(1)} $\n",
    "        - $ db^{(1)} = \\frac{1}{m} \\sum_{i=1}^{m} dZ^{(1)} $\n",
    "    - Where:\n",
    "        - $ m $ is the number of training examples.\n",
    "        - $ y $ is the ground truth labels.\n",
    "        - $ dZ^{(2)} $ is the gradient of the loss function with respect to the output of the output layer.\n",
    "        - $ dZ^{(1)} $ is the gradient of the loss function with respect to the output of the hidden layer.\n",
    "        - $ dW^{(2)} $ and $ dW^{(1)} $ are the gradients of the loss function with respect to the weights of the output and hidden layers, respectively.\n",
    "        - $ db^{(2)} $ and $ db^{(1)} $ are the gradients of the loss function with respect to the biases of the output and hidden layers, respectively.\n",
    "\n",
    "5. **Parameter Initialization**: We initialize the weights and biases of the neural network using random values. This ensures that the model starts with different parameters in each training session, which helps prevent the model from getting stuck in local minima.\n",
    "\n",
    "6. **Parameter Update**: The `update_parameters` function adjusts the weights and biases of the neural network based on the gradients computed during the backward pass. This step is crucial for optimizing the model and reducing the loss.\n",
    "\n",
    "7. **Training**: The `train` function trains the neural network using the provided training data. It iteratively performs forward and backward passes, updating the parameters to minimize the loss function.\n",
    "\n",
    "8. **Prediction**: Finally, the `predict` function makes predictions using the trained neural network model. It applies the forward pass to the input data and returns the predicted class labels based on the output probabilities.\n",
    "\n",
    "By following these steps, we create a flexible and customizable MLP capable of effectively handling binary classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for sigmoid activation\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid activation function.\n",
    "    \n",
    "    Parameters:\n",
    "    x (numpy.ndarray): Input data.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: Output data.\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for forward pass\n",
    "def forward(X, W1, b1, W2, b2):\n",
    "    \"\"\"\n",
    "    Perform the forward pass of the neural network.\n",
    "    \n",
    "    Parameters:\n",
    "    X (numpy.ndarray): Input data.\n",
    "    W1 (numpy.ndarray): Weights of the first layer.\n",
    "    b1 (numpy.ndarray): Biases of the first layer.\n",
    "    W2 (numpy.ndarray): Weights of the second layer.\n",
    "    b2 (numpy.ndarray): Biases of the second layer.\n",
    "    \n",
    "    Returns:\n",
    "    tuple of size 4:\n",
    "        numpy.ndarray: Output of the first layer before activation.\n",
    "        numpy.ndarray: Output of the first layer after activation.\n",
    "        numpy.ndarray: Output of the second layer before activation.\n",
    "        numpy.ndarray: Output of the second layer after activation.\n",
    "    \"\"\"\n",
    "     \n",
    "    Z1 = np.dot(X, W1) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    return Z1, A1, Z2, A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for computing loss\n",
    "def compute_loss(y, A2):\n",
    "    \"\"\"\n",
    "    Compute the binary cross-entropy loss.\n",
    "    \n",
    "    Parameters:\n",
    "    y (numpy.ndarray): Ground truth labels.\n",
    "    A2 (numpy.ndarray): Predicted probabilities.\n",
    "    \n",
    "    Returns:\n",
    "    float: Binary cross-entropy loss.\n",
    "    \"\"\"\n",
    "    loss = -np.mean(y * np.log(A2) + (1 - y) * np.log(1 - A2))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for backward pass\n",
    "def backward(X, y, A1, A2, W2):\n",
    "    \"\"\" \n",
    "    Perform the backward pass of the neural network.\n",
    "    \n",
    "    Parameters:\n",
    "    X (numpy.ndarray): Input data.\n",
    "    y (numpy.ndarray): Ground truth labels.\n",
    "    A1 (numpy.ndarray): Output of the first layer after activation.\n",
    "    A2 (numpy.ndarray): Output of the second layer after activation.\n",
    "    W2 (numpy.ndarray): Weights of the second layer.\n",
    "    \n",
    "    Returns:\n",
    "    tuple of size 4:\n",
    "        numpy.ndarray: Gradient of the weights of the first layer.\n",
    "        numpy.ndarray: Gradient of the biases of the first layer.\n",
    "        numpy.ndarray: Gradient of the weights of the second layer.\n",
    "        numpy.ndarray: Gradient of the biases of the second layer.\n",
    "    \"\"\"\n",
    "    m = len(y)\n",
    "    dZ2 = A2 - y\n",
    "    dW2 = np.dot(A1.T, dZ2) / m\n",
    "    db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
    "    dZ1 = np.dot(dZ2, W2.T) * A1 * (1 - A1)\n",
    "    dW1 = np.dot(X.T, dZ1) / m\n",
    "    db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
    "    return dW1, db1, dW2, db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for parameter initialization\n",
    "def initialize_parameters(input_size, hidden_size, output_size):\n",
    "    \"\"\"\n",
    "    Initialize the weights and biases of the neural network.\n",
    "    \n",
    "    Parameters:\n",
    "    input_size (int): Number of input features.\n",
    "    hidden_size (int): Number of units in the hidden layer.\n",
    "    output_size (int): Number of output units.\n",
    "    \n",
    "    Returns:\n",
    "    tuple of size 4:\n",
    "        numpy.ndarray: Weights of the first layer.\n",
    "        numpy.ndarray: Biases of the first layer.\n",
    "        numpy.ndarray: Weights of the second layer.\n",
    "        numpy.ndarray: Biases of the second layer.\n",
    "    \"\"\"\n",
    "    \n",
    "    W1 = np.random.randn(input_size, hidden_size)\n",
    "    b1 = np.zeros((1, hidden_size))\n",
    "    W2 = np.random.randn(hidden_size, output_size)\n",
    "    b2 = np.zeros((1, output_size))\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for updating parameters\n",
    "def update_parameters(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate):\n",
    "    \"\"\" \n",
    "    Update the weights and biases of the neural network.\n",
    "    \n",
    "    Parameters:\n",
    "    W1 (numpy.ndarray): Weights of the first layer.\n",
    "    b1 (numpy.ndarray): Biases of the first layer.\n",
    "    W2 (numpy.ndarray): Weights of the second layer.\n",
    "    b2 (numpy.ndarray): Biases of the second layer.\n",
    "    dW1 (numpy.ndarray): Gradient of the weights of the first layer.\n",
    "    db1 (numpy.ndarray): Gradient of the biases of the first layer.\n",
    "    dW2 (numpy.ndarray): Gradient of the weights of the second layer.\n",
    "    db2 (numpy.ndarray): Gradient of the biases of the second layer.\n",
    "    learning_rate (float): Learning rate.\n",
    "    \n",
    "    Returns:\n",
    "    tuple of size 4:\n",
    "        numpy.ndarray: Updated weights of the first layer.\n",
    "        numpy.ndarray: Updated biases of the first layer.\n",
    "        numpy.ndarray: Updated weights of the second layer.\n",
    "        numpy.ndarray: Updated biases of the second layer.\n",
    "    \"\"\"\n",
    "    \n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for training the model\n",
    "def train(X_train, y_train, X_test, y_test, num_hidden_units, learning_rate, num_epochs, mini_batch_size):\n",
    "    \"\"\"\n",
    "    Train the neural network model.\n",
    "    \n",
    "    Parameters:\n",
    "    X_train (numpy.ndarray): Training data.\n",
    "    y_train (numpy.ndarray): Training labels.\n",
    "    X_test (numpy.ndarray): Test data.\n",
    "    y_test (numpy.ndarray): Test labels.\n",
    "    num_hidden_units (int): Number of units in the hidden layer.\n",
    "    learning_rate (float): Learning rate.\n",
    "    num_epochs (int): Number of epochs.\n",
    "    mini_batch_size (int): Size of mini-batches.\n",
    "    \n",
    "    Returns:\n",
    "    tuple of size 6:\n",
    "        numpy.ndarray: Weights of the first layer.\n",
    "        numpy.ndarray: Biases of the first layer.\n",
    "        numpy.ndarray: Weights of the second layer.\n",
    "        numpy.ndarray: Biases of the second layer.\n",
    "        list: Training losses for each epoch.\n",
    "        list: Validation losses for each epoch.\n",
    "    \"\"\"\n",
    "    input_size = X_train.shape[1]\n",
    "    output_size = 1  # Binary classification\n",
    "    W1, b1, W2, b2 = initialize_parameters(input_size, num_hidden_units, output_size)\n",
    "\n",
    "    train_losses = []\n",
    "    validation_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle training data\n",
    "        permutation = np.random.permutation(len(X_train))\n",
    "        X_train_shuffled = X_train[permutation]\n",
    "        y_train_shuffled = y_train[permutation]\n",
    "\n",
    "        for i in range(0, len(X_train_shuffled), mini_batch_size):\n",
    "            # Mini-batch training\n",
    "            X_batch = X_train_shuffled[i:i+mini_batch_size]\n",
    "            y_batch = y_train_shuffled[i:i+mini_batch_size]\n",
    "\n",
    "            # Forward pass\n",
    "            Z1, A1, Z2, A2 = forward(X_batch, W1, b1, W2, b2)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = compute_loss(y_batch, A2)\n",
    "\n",
    "            # Backward pass\n",
    "            dW1, db1, dW2, db2 = backward(X_batch, y_batch, A1, A2, W2)\n",
    "\n",
    "            # Update parameters\n",
    "            W1, b1, W2, b2 = update_parameters(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)\n",
    "\n",
    "        # Compute training and validation losses\n",
    "        _, _, _, train_loss = forward(X_train, W1, b1, W2, b2)\n",
    "        _, _, _, validation_loss = forward(X_test, W1, b1, W2, b2)\n",
    "        train_losses.append(train_loss)\n",
    "        validation_losses.append(validation_loss)\n",
    "\n",
    "        # Print loss every 50 epochs\n",
    "        if epoch % 50 == 0:\n",
    "            print(f\"Epoch {epoch}: Loss = {loss}\")\n",
    "\n",
    "    return W1, b1, W2, b2, train_losses, validation_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for making predictions\n",
    "def predict(X, W1, b1, W2, b2):\n",
    "    \"\"\"\n",
    "    Make predictions using the trained neural network model.\n",
    "    \n",
    "    Parameters:\n",
    "    X (numpy.ndarray): Input data.\n",
    "    W1 (numpy.ndarray): Weights of the first layer.\n",
    "    b1 (numpy.ndarray): Biases of the first layer.\n",
    "    W2 (numpy.ndarray): Weights of the second layer.\n",
    "    b2 (numpy.ndarray): Biases of the second layer.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: Predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    _, _, _, A2 = forward(X, W1, b1, W2, b2)\n",
    "    predictions = (A2 > 0.5).astype(int)\n",
    "    return predictions.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small note on data:\n",
    "The dataset contained ordered values (by target), which caused a lot of bias in the model. This was also demonstrated by the metrics of the model. To solve this problem, the dataset was shuffled before training the model. This helped to reduce the bias in the model and improve the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 0.19041322387292386\n",
      "Epoch 50: Loss = 0.9886245046298728\n",
      "Epoch 100: Loss = 0.5369816984264681\n",
      "Epoch 150: Loss = 0.6237312406650859\n",
      "Epoch 200: Loss = 0.09732462782789472\n"
     ]
    }
   ],
   "source": [
    "# Very important step: Shuffling the data. This is because the data is ordered by target, \n",
    "# so if we don't shuffle it, we will have all the 0s and then all the 1s.\n",
    "heart_data = heart_data.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "\n",
    "# Preprocessing\n",
    "X = heart_data.drop(columns=['target'])  # Exclude the target column\n",
    "y = heart_data['target'].values.reshape(-1, 1)\n",
    "\n",
    "# Normalize features using Z-score normalization\n",
    "X_normalized = z_score_normalization(X)\n",
    "\n",
    "# Perform one-hot encoding for categorical variables\n",
    "categorical_cols = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal']\n",
    "X_encoded = pd.concat([pd.get_dummies(X_normalized[col], prefix=col, drop_first=True) for col in categorical_cols], axis=1)\n",
    "\n",
    "# Concatenate the encoded features with the non-categorical features\n",
    "non_categorical_cols = [col for col in X_normalized.columns if col not in categorical_cols]\n",
    "X_encoded = pd.concat([X_encoded, X_normalized[non_categorical_cols]], axis=1)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(X_encoded) * split_ratio)\n",
    "X_train, X_test = X_encoded[:split_index].values, X_encoded[split_index:].values\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "# Train the model and get training and validation losses\n",
    "num_hidden_units = 5\n",
    "learning_rate = 0.01\n",
    "num_epochs = 250\n",
    "mini_batch_size = 4\n",
    "\n",
    "W1, b1, W2, b2, train_losses, validation_losses = train(X_train, y_train, X_test, y_test, num_hidden_units, learning_rate, num_epochs, mini_batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = predict(X_test, W1, b1, W2, b2)\n",
    "\n",
    "# Plot the training and validation losses\n",
    "mean_train_losses = np.mean(train_losses, axis=1)\n",
    "mean_validation_losses = np.mean(validation_losses, axis=1)\n",
    "\n",
    "epochs = range(num_epochs)\n",
    "plt.plot(epochs, mean_train_losses, label='Training Loss')\n",
    "plt.plot(epochs, mean_validation_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in order to evaluate the final model, we will have to compute the following metrics :\n",
    "1. the precision of your model\n",
    "2. the accuracy of your model\n",
    "3. the sensitivity of your model\n",
    "4. the specificity of your model\n",
    "\n",
    "To compute the specified metrics for model evaluation, we can use the following formulas:\n",
    "\n",
    "1. Precision: Precision measures the proportion of true positive predictions among all positive predictions made by the model.\n",
    "   $$\n",
    "   \\text{Precision} = \\frac{TP}{TP + FP}\n",
    "   $$\n",
    "   Where:\n",
    "   - \\( TP \\) is the number of true positive predictions.\n",
    "   - \\( FP \\) is the number of false positive predictions.\n",
    "\n",
    "2. Accuracy: Accuracy measures the proportion of correct predictions among all predictions made by the model.\n",
    "   $$\n",
    "   \\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "   $$\n",
    "   Where:\n",
    "   - \\( TP \\) is the number of true positive predictions.\n",
    "   - \\( TN \\) is the number of true negative predictions.\n",
    "   - \\( FP \\) is the number of false positive predictions.\n",
    "   - \\( FN \\) is the number of false negative predictions.\n",
    "\n",
    "3. Sensitivity (True Positive Rate or Recall): Sensitivity measures the proportion of actual positive instances that are correctly identified by the model.\n",
    "   $$\n",
    "   \\text{Sensitivity} = \\frac{TP}{TP + FN}\n",
    "   $$\n",
    "   Where:\n",
    "   - \\( TP \\) is the number of true positive predictions.\n",
    "   - \\( FN \\) is the number of false negative predictions.\n",
    "\n",
    "4. Specificity (True Negative Rate): Specificity measures the proportion of actual negative instances that are correctly identified by the model.\n",
    "   $$\n",
    "   \\text{Specificity} = \\frac{TN}{TN + FP}\n",
    "   $$\n",
    "   Where:\n",
    "   - \\( TN \\) is the number of true negative predictions.\n",
    "   - \\( FP \\) is the number of false positive predictions.\n",
    "\n",
    "We can compute these metrics using the predicted labels (`predictions`) and the true labels (`y_test`). Then, we can calculate the required values and print or store the results for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute precision, accuracy, sensitivity, and specificity metrics.\n",
    "\n",
    "    Parameters:\n",
    "    y_true (numpy.ndarray): True labels.\n",
    "    y_pred (numpy.ndarray): Predicted labels.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Precision, accuracy, sensitivity, and specificity metrics.\n",
    "    \"\"\"\n",
    "    # True positives (TP), true negatives (TN), false positives (FP), false negatives (FN)\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "\n",
    "    # Precision\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "    # Sensitivity (True Positive Rate or Recall)\n",
    "    sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "    # Specificity (True Negative Rate)\n",
    "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "\n",
    "    return precision, accuracy, sensitivity, specificity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7941176470588235\n",
      "Accuracy: 0.819672131147541\n",
      "Sensitivity: 0.8709677419354839\n",
      "Specificity: 0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "precision, accuracy, sensitivity, specificity = compute_metrics(y_test.flatten(), predictions.flatten())\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Multilayer Perceptron (MLP) model exhibits strong performance in predicting the risk of heart disease:\n",
    "\n",
    "- Precision: Approximately 79.41% of positive predictions are accurate.\n",
    "- Accuracy: Correctly predicts outcomes for about 81.97% of instances.\n",
    "- Sensitivity: Identifies around 87.10% of actual positive instances.\n",
    "- Specificity: Accurately identifies around 76.67% of actual negative instances.\n",
    "\n",
    "Overall, the MLP model demonstrates high precision and specificity, indicating its effectiveness in identifying both positive and negative instances of heart disease. However, sensitivity is slightly lower, suggesting some instances of heart disease may be missed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** In the case of predicting the risk of heart disease in patients, would you prefer that your\n",
    "model is sensitive or specific?\n",
    "\n",
    "**Answer:** In the case of predicting heart disease risk, it's preferable for the model to be sensitive. This ensures it correctly identifies individuals with the disease, minimizing false negatives and ensuring those at risk receive appropriate care."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to make predictions using Decision Tree, and compare it afterwards with the MLP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    \"\"\"\n",
    "    A simple implementation of a Decision Tree classifier for binary classification.\n",
    "\n",
    "    Attributes:\n",
    "        max_depth (int): The maximum depth of the decision tree.\n",
    "        tree: The learned decision tree structure.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_depth=4):\n",
    "        \"\"\"\n",
    "        Initialize the DecisionTreeClassifier.\n",
    "\n",
    "        Args:\n",
    "            max_depth (int): The maximum depth of the decision tree. Default is 4.\n",
    "        \"\"\"\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the decision tree classifier to the training data.\n",
    "\n",
    "        Args:\n",
    "            X (numpy.ndarray): The input features.\n",
    "            y (numpy.ndarray): The target labels.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.tree = self._build_tree(X, y, depth=0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the target labels for the input data.\n",
    "\n",
    "        Args:\n",
    "            X (numpy.ndarray): The input features.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Predicted target labels.\n",
    "        \"\"\"\n",
    "        return np.array([self._predict_tree(x, self.tree) for x in X])\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        \"\"\"\n",
    "        Recursively build the decision tree.\n",
    "\n",
    "        Args:\n",
    "            X (numpy.ndarray): The input features.\n",
    "            y (numpy.ndarray): The target labels.\n",
    "            depth (int): The current depth of the tree.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple representing the decision tree node.\n",
    "        \"\"\"\n",
    "        if depth >= self.max_depth or len(np.unique(y)) == 1:\n",
    "            return np.bincount(y.flatten()).argmax()\n",
    "\n",
    "        num_features = X.shape[1]\n",
    "        best_feature, best_threshold = None, None\n",
    "        best_gini = float('inf')\n",
    "\n",
    "        for feature in range(num_features):\n",
    "            thresholds = np.unique(X[:, feature])\n",
    "            for threshold in thresholds:\n",
    "                left_indices = np.where(X[:, feature] <= threshold)[0]\n",
    "                right_indices = np.where(X[:, feature] > threshold)[0]\n",
    "\n",
    "                left_gini = self._gini_impurity(y[left_indices])\n",
    "                right_gini = self._gini_impurity(y[right_indices])\n",
    "\n",
    "                gini = (len(left_indices) * left_gini + len(right_indices) * right_gini) / len(y)\n",
    "                if gini < best_gini:\n",
    "                    best_feature, best_threshold, best_gini = feature, threshold, gini\n",
    "\n",
    "        if best_gini == float('inf'):\n",
    "            return np.bincount(y.flatten()).argmax()\n",
    "\n",
    "        left_indices = np.where(X[:, best_feature] <= best_threshold)[0]\n",
    "        right_indices = np.where(X[:, best_feature] > best_threshold)[0]\n",
    "\n",
    "        print(f\"Depth: {depth}, Feature: {best_feature}, Threshold: {best_threshold}, Left samples: {len(left_indices)}, Right samples: {len(right_indices)}\")\n",
    "\n",
    "        left_subtree = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right_subtree = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "        return (best_feature, best_threshold, left_subtree, right_subtree)\n",
    "\n",
    "    def _predict_tree(self, x, tree):\n",
    "        \"\"\"\n",
    "        Recursively traverse the decision tree to predict the label of a single instance.\n",
    "\n",
    "        Args:\n",
    "            x (numpy.ndarray): A single instance of input features.\n",
    "            tree: The decision tree node.\n",
    "\n",
    "        Returns:\n",
    "            int: The predicted label.\n",
    "        \"\"\"\n",
    "        if isinstance(tree, int):  # Check if it's a leaf node\n",
    "            return tree  # Return the predicted class directly\n",
    "        else:\n",
    "            try:\n",
    "                feature, threshold, left_subtree, right_subtree = tree\n",
    "            except (ValueError, TypeError):\n",
    "                return tree  # Return the predicted class if tree is an integer (leaf node)\n",
    "            if x[feature] <= threshold:\n",
    "                return self._predict_tree(x, left_subtree)\n",
    "            else:\n",
    "                return self._predict_tree(x, right_subtree)\n",
    "\n",
    "    def _gini_impurity(self, y):\n",
    "        \"\"\"\n",
    "        Calculate the Gini impurity for a set of target labels.\n",
    "\n",
    "        Args:\n",
    "            y (numpy.ndarray): The target labels.\n",
    "\n",
    "        Returns:\n",
    "            float: The Gini impurity.\n",
    "        \"\"\"\n",
    "        if len(y) == 0:\n",
    "            return 0\n",
    "        probabilities = np.bincount(y.flatten()) / len(y)\n",
    "        return 1 - np.sum(probabilities ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 0, Feature: 11, Threshold: 0.0, Left samples: 110, Right samples: 132\n",
      "Depth: 1, Feature: 17, Threshold: -0.46474512855737066, Left samples: 33, Right samples: 77\n",
      "Depth: 2, Feature: 15, Threshold: -0.23661679927223564, Left samples: 19, Right samples: 14\n",
      "Depth: 3, Feature: 16, Threshold: -0.0718992841048539, Left samples: 6, Right samples: 13\n",
      "Depth: 3, Feature: 14, Threshold: -0.6627704255708822, Left samples: 2, Right samples: 12\n",
      "Depth: 2, Feature: 3, Threshold: 0.0, Left samples: 70, Right samples: 7\n",
      "Depth: 3, Feature: 2, Threshold: 0.0, Left samples: 54, Right samples: 16\n",
      "Depth: 3, Feature: 14, Threshold: -0.6627704255708822, Left samples: 2, Right samples: 5\n",
      "Depth: 1, Feature: 17, Threshold: 0.8271610544966046, Left samples: 123, Right samples: 9\n",
      "Depth: 2, Feature: 18, Threshold: -0.7132489707470252, Left samples: 88, Right samples: 35\n",
      "Depth: 3, Feature: 13, Threshold: 0.40009061453978684, Left samples: 68, Right samples: 20\n",
      "Depth: 3, Feature: 2, Threshold: 0.0, Left samples: 24, Right samples: 11\n",
      "Depth: 2, Feature: 4, Threshold: 0.0, Left samples: 8, Right samples: 1\n",
      "Precision: 0.8571428571428571\n",
      "Accuracy: 0.819672131147541\n",
      "Sensitivity: 0.7741935483870968\n",
      "Specificity: 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "X = heart_data.drop(columns=['target'])  # Exclude the target column\n",
    "y = heart_data['target']  # No need to reshape here\n",
    "\n",
    "# Normalize features using Z-score normalization\n",
    "X_normalized = z_score_normalization(X)\n",
    "\n",
    "# Perform one-hot encoding for categorical variables\n",
    "categorical_cols = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal']\n",
    "X_encoded = pd.concat([pd.get_dummies(X_normalized[col], prefix=col, drop_first=True) for col in categorical_cols], axis=1)\n",
    "\n",
    "# Concatenate the encoded features with the non-categorical features\n",
    "non_categorical_cols = [col for col in X_normalized.columns if col not in categorical_cols]\n",
    "X_encoded = pd.concat([X_encoded, X_normalized[non_categorical_cols]], axis=1)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(X_encoded) * split_ratio)\n",
    "X_train, X_test = X_encoded[:split_index].values, X_encoded[split_index:].values\n",
    "y_train, y_test = y[:split_index].values.ravel(), y[split_index:].values.ravel()  # Ensure y is flattened\n",
    "\n",
    "# Initialize and train the decision tree classifier\n",
    "decision_tree = DecisionTreeClassifier(max_depth=4)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the same dataset for demonstration purposes\n",
    "predictions = decision_tree.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "precision, accuracy, sensitivity, specificity = compute_metrics(y_test, predictions)\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"Specificity: {specificity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When assessing the performance of the Decision Tree (DT) model in predicting the risk of heart disease, the results indicate:\n",
    "\n",
    "- Precision: Approximately 85.71% of positive predictions are accurate.\n",
    "- Accuracy: Correctly predicts outcomes for about 81.97% of instances.\n",
    "- Sensitivity: Identifies around 77.42% of actual positive instances.\n",
    "- Specificity: Accurately identifies around 86.67% of actual negative instances.\n",
    "\n",
    "These metrics indicate that the Decision Tree model achieves high precision and specificity, suggesting its effectiveness in correctly classifying positive instances of heart disease and distinguishing between positive and negative instances. However, it has slightly lower sensitivity compared to the Multilayer Perceptron model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of MLP and Decision Tree Models\n",
    "\n",
    "Based on the evaluation metrics obtained for both the Multilayer Perceptron (MLP) and Decision Tree (DT) models in predicting the risk of heart disease, it is essential to assess their effectiveness in practical applications. While both models exhibit strengths in certain aspects, a comprehensive evaluation is necessary to determine the preferred model for predicting heart disease risk. Let's compare the performance of both models based on the provided evaluation metrics:\n",
    "\n",
    "**Multilayer Perceptron (MLP):**\n",
    "- Precision: 0.794\n",
    "- Accuracy: 0.820\n",
    "- Sensitivity: 0.871\n",
    "- Specificity: 0.767\n",
    "\n",
    "**Decision Tree (DT):**\n",
    "- Precision: 0.857\n",
    "- Accuracy: 0.820\n",
    "- Sensitivity: 0.774\n",
    "- Specificity: 0.867\n",
    "\n",
    "Upon comparison, both models demonstrate relatively similar accuracy and specificity. However, the MLP model exhibits higher sensitivity, suggesting it is better at identifying individuals with heart disease when they are truly present. On the other hand, the DT model shows slightly higher precision, indicating its ability to minimize false positives.\n",
    "\n",
    "Considering these aspects, if the priority is to accurately identify individuals with heart disease, the MLP model might be preferred due to its higher sensitivity. Conversely, if reducing false positives is crucial, the DT model could be favored due to its higher precision. Ultimately, the choice between the two models depends on the specific requirements and constraints of the application, balancing the trade-offs between sensitivity and precision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
