{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# AI Practical Work â„–4\n",
    "\n",
    "### Team: Murad Mustafayev & Kamal Ahmadov\n",
    "\n",
    "### CS-20"
   ],
   "metadata": {
    "id": "E4qkvj-3RG2e"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 Questions:\n",
    "\n",
    "  **How are the weights initialized ?**\n",
    "\n",
    "Various methods for weight initialization include random initialization, Xavier initialization, He initialization, Uniform initialization, and Normal initialization. In this scenario, we opted for random initialization.\n",
    "\n",
    "**Which activation functions are available to you in NNLib ?**\n",
    "\n",
    "Since we use Python, not Java, we don't know about NNLib library, and all the codes will be presented from scratch. However, some common activation functions are:  softmax, linear activation, hyperbolic tangent, softplus, exponential linear unit, etc.\n",
    "\n",
    "**Since you are dealing with a classification problem, what activation function will you use for your output layer ?**\n",
    "\n",
    "Considering the classification task, we will utilize the softmax function for the output layer.\n",
    "\n",
    "  **What cost function is available to you ?**\n",
    "\n",
    "The common cost functions are: Mean Squared Error, Binary Cross-Entropy Loss, Categorical Cross-Entropy Loss, Sparse Categorical Cross-Entropy Loss, Hinge Loss, and Kullback-Leibler Divergence.\n",
    "Since we are dealing with multiclass classification, we use Categorical Cross-Entropy Loss.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 Questions:\n",
    "  **What proportion of the data are held for training ? for testing ?**\n",
    "\n",
    "It's a common practice to sample 70-80% of the data for training and 20-30% for testing.\n",
    "For more complex models the data is sampled as: 20% for test, 20% for validation and 60% for training.\n",
    "In this case we use 80% for training and 20% for test.\n",
    "\n",
    "  **What is contained in X train (resp. X test) and Y train (resp. Y test) ?**\n",
    "\n",
    "In the iris dataset for a classification task, X train contains features (sepal length, sepal width, petal length, and petal width) of training samples, while Y train contains corresponding species labels. Similarly, X test contains features of test samples, and Y test contains corresponding species labels.\n",
    "\n",
    "  **How many hidden layers are used in this network ? How many units are there per layer ?**\n",
    "\n",
    "For this practical work one hidden layer with 64 total 64 units was used."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# One hot encoding and decoding functions for labels\n",
    "\n",
    "def one_hot_encode(labels, num_classes):\n",
    "    \"\"\"\n",
    "    Convert an array of labels to one-hot encoding.\n",
    "\n",
    "    Parameters:\n",
    "        labels (array-like): Array of labels.\n",
    "        num_classes (int): Number of classes.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: One-hot encoded labels.\n",
    "    \"\"\"\n",
    "    num_samples = len(labels)\n",
    "    one_hot_labels = np.zeros((num_samples, num_classes))\n",
    "    one_hot_labels[np.arange(num_samples), labels] = 1\n",
    "    return one_hot_labels\n",
    "\n",
    "def one_hot_decode(one_hot_labels, label_names):\n",
    "    \"\"\"\n",
    "    Decode one-hot encoded labels to original labels.\n",
    "\n",
    "    Parameters:\n",
    "        one_hot_labels (numpy.ndarray): One-hot encoded labels.\n",
    "        label_names (list): List of label names.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Decoded labels.\n",
    "    \"\"\"\n",
    "    decoded_labels = np.argmax(one_hot_labels, axis=1)\n",
    "    return np.array([label_names[label] for label in decoded_labels])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fUtg5PJbCfOo"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        \"\"\"\n",
    "        Initialize the neural network with given input, hidden, and output sizes.\n",
    "\n",
    "        Parameters:\n",
    "            input_size (int): Number of input features.\n",
    "            hidden_size (int): Number of units in the hidden layer.\n",
    "            output_size (int): Number of output units.\n",
    "        \"\"\"\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self._initialize_parameters()\n",
    "\n",
    "    def _initialize_parameters(self):\n",
    "        \"\"\"\n",
    "        Initialize weights and biases for the neural network.\n",
    "        \"\"\"\n",
    "        self.W1 = np.random.randn(self.input_size, self.hidden_size)\n",
    "        self.b1 = np.zeros((1, self.hidden_size))\n",
    "        self.W2 = np.random.randn(self.hidden_size, self.output_size)\n",
    "        self.b2 = np.zeros((1, self.output_size))\n",
    "\n",
    "    @staticmethod\n",
    "    def _softmax(Z):\n",
    "        \"\"\"\n",
    "        Compute the softmax function.\n",
    "\n",
    "        Parameters:\n",
    "            Z (numpy.ndarray): Input matrix.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Softmax output.\n",
    "        \"\"\"\n",
    "        exp_Z = np.exp(Z - np.max(Z, axis=1, keepdims=True))\n",
    "        softmax_output = exp_Z / np.sum(exp_Z, axis=1, keepdims=True)\n",
    "        return softmax_output\n",
    "\n",
    "    def _forward_pass(self, X_batch):\n",
    "        \"\"\"\n",
    "        Perform a forward pass through the neural network.\n",
    "\n",
    "        Parameters:\n",
    "            X_batch (numpy.ndarray): Input data batch.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[numpy.ndarray, numpy.ndarray]: Predictions and hidden layer activations.\n",
    "        \"\"\"\n",
    "        Z1 = np.dot(X_batch, self.W1) + self.b1\n",
    "        A1 = np.tanh(Z1)\n",
    "\n",
    "        Z2 = np.dot(A1, self.W2) + self.b2\n",
    "        predictions = self._softmax(Z2)\n",
    "\n",
    "        return predictions, A1\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_loss(predictions, Y_batch):\n",
    "        \"\"\"\n",
    "        Compute the loss between predictions and actual labels.\n",
    "\n",
    "        Parameters:\n",
    "            predictions (numpy.ndarray): Predicted probabilities.\n",
    "            Y_batch (numpy.ndarray): True labels.\n",
    "\n",
    "        Returns:\n",
    "            float: Loss value.\n",
    "        \"\"\"\n",
    "        num_samples = len(Y_batch)\n",
    "        loss = -np.sum(Y_batch * np.log(predictions)) / num_samples\n",
    "        return loss\n",
    "\n",
    "    def _backpropagation(self, X_batch, Y_batch, predictions, hidden_layer_output):\n",
    "        \"\"\"\n",
    "        Perform backpropagation to compute gradients.\n",
    "\n",
    "        Parameters:\n",
    "            X_batch (numpy.ndarray): Input data batch.\n",
    "            Y_batch (numpy.ndarray): True labels.\n",
    "            predictions (numpy.ndarray): Predicted probabilities.\n",
    "            hidden_layer_output (numpy.ndarray): Activations of the hidden layer.\n",
    "\n",
    "        Returns:\n",
    "            dict: Gradients of the parameters.\n",
    "        \"\"\"\n",
    "        num_samples = len(Y_batch)\n",
    "        dZ2 = predictions - Y_batch\n",
    "        dW2 = (1 / num_samples) * np.dot(hidden_layer_output.T, dZ2)\n",
    "        db2 = (1 / num_samples) * np.sum(dZ2, axis=0, keepdims=True)\n",
    "        dZ1 = np.dot(dZ2, self.W2.T) * (1 - np.power(np.tanh(np.dot(X_batch, self.W1) + self.b1), 2))\n",
    "        dW1 = (1 / num_samples) * np.dot(X_batch.T, dZ1)\n",
    "        db1 = (1 / num_samples) * np.sum(dZ1, axis=0, keepdims=True)\n",
    "\n",
    "        gradients = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2}\n",
    "        return gradients\n",
    "\n",
    "    def _update_parameters(self, gradients, learning_rate):\n",
    "        \"\"\"\n",
    "        Update parameters using gradients and learning rate.\n",
    "\n",
    "        Parameters:\n",
    "            gradients (dict): Gradients of the parameters.\n",
    "            learning_rate (float): Learning rate for parameter updates.\n",
    "        \"\"\"\n",
    "        self.W1 -= learning_rate * gradients[\"dW1\"]\n",
    "        self.b1 -= learning_rate * gradients[\"db1\"]\n",
    "        self.W2 -= learning_rate * gradients[\"dW2\"]\n",
    "        self.b2 -= learning_rate * gradients[\"db2\"]\n",
    "\n",
    "    @staticmethod\n",
    "    def _split_batches(X_train, Y_train, batch_size):\n",
    "        \"\"\"\n",
    "        Split data into batches.\n",
    "\n",
    "        Parameters:\n",
    "            X_train (numpy.ndarray): Input data.\n",
    "            Y_train (numpy.ndarray): True labels.\n",
    "            batch_size (int): Size of each batch.\n",
    "\n",
    "        Yields:\n",
    "            Tuple[numpy.ndarray, numpy.ndarray]: Batches of input data and true labels.\n",
    "        \"\"\"\n",
    "        num_batches = len(X_train) // batch_size\n",
    "        for i in range(num_batches):\n",
    "            start_idx = i * batch_size\n",
    "            end_idx = (i + 1) * batch_size\n",
    "            yield X_train[start_idx:end_idx], Y_train[start_idx:end_idx]\n",
    "\n",
    "    def train(self, X_train, Y_train, epochs, batch_size, learning_rate):\n",
    "        \"\"\"\n",
    "        Train the neural network.\n",
    "\n",
    "        Parameters:\n",
    "            X_train (numpy.ndarray): Training input data.\n",
    "            Y_train (numpy.ndarray): Training true labels.\n",
    "            epochs (int): Number of training epochs.\n",
    "            batch_size (int): Size of each batch.\n",
    "            learning_rate (float): Learning rate for parameter updates.\n",
    "\n",
    "        Returns:\n",
    "            list: List of loss values for each epoch.\n",
    "        \"\"\"\n",
    "        loss_list = []\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for X_batch, Y_batch in self._split_batches(X_train, Y_train, batch_size):\n",
    "                predictions, hidden_layer_output = self._forward_pass(X_batch)\n",
    "                loss = self._compute_loss(predictions, Y_batch)\n",
    "                total_loss += loss\n",
    "                gradients = self._backpropagation(X_batch, Y_batch, predictions, hidden_layer_output)\n",
    "                self._update_parameters(gradients, learning_rate)\n",
    "            avg_loss = total_loss / len(X_train)\n",
    "            loss_list.append(avg_loss)\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "        return loss_list\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions on test data.\n",
    "\n",
    "        Parameters:\n",
    "            X (numpy.ndarray): Test input data.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Predicted labels.\n",
    "        \"\"\"\n",
    "        predictions, _ = self._forward_pass(X)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Questions\n",
    "\n",
    "  **What is an epoch of training ?**\n",
    "\n",
    "An epoch of training signifies completing a full iteration through the entire training dataset. Essentially, within one epoch, the neural network model processes each training sample once.\n",
    "  \n",
    "  **Say we want to train on batches of size n. How will you implement an epoch of training ?**\n",
    "\n",
    "  To execute an epoch of training with batches of size n, we'd segment the training dataset into batches of size n and iterate over them. For every batch, a forward pass is conducted to compute predictions, followed by loss computation, backpropagation for gradient calculation, and parameter updates. This cycle repeats for each batch until all batches are processed, thereby concluding one epoch.\n",
    "  \n",
    "  **We know how to measure the error between our predictions and the expected labels on the output\n",
    "  label. Do we have target values for the hidden units ? How can we update the parameters on those\n",
    "  hidden units ?**\n",
    "\n",
    " Hidden units lack target values during training, unlike output layer units which represent the ground truth labels. Hidden units function as intermediary representations of input data and do not possess explicit target values during training. Instead, parameters (weights and biases) of hidden units are updated based on their contribution to minimizing error in the output layer. This is accomplished through backpropagation, where gradients are computed with respect to the loss function and propagated backward through the network, updating parameters at each layer, including the hidden layers."
   ],
   "metadata": {
    "id": "ERVNguGOJtrg"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "label_names = iris.target_names\n",
    "\n",
    "# Split dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = len(np.unique(y))\n",
    "Y_train = one_hot_encode(y_train, num_classes)\n",
    "\n",
    "# Initialize neural network\n",
    "input_size = X.shape[1]\n",
    "hidden_size = 64\n",
    "output_size = num_classes\n",
    "nn = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "\n",
    "# Train neural network\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "learning_rate = 0.01\n",
    "loss_list = nn.train(X_train, Y_train, epochs, batch_size, learning_rate)\n",
    "\n",
    "# Make predictions on test set\n",
    "predicted_labels = nn.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, predicted_labels)\n",
    "print(f\"Accuracy on test set: {accuracy:.4f}\")\n",
    "\n",
    "# Plot loss curve\n",
    "plt.plot(loss_list)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Cross-Entropy Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "cdE5cxZNCi0M",
    "outputId": "dcad5108-de93-4886-8a1c-6517f024b131"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100, Average Loss: 7.7444\n",
      "Epoch 2/100, Average Loss: 4.0575\n",
      "Epoch 3/100, Average Loss: 2.7073\n",
      "Epoch 4/100, Average Loss: 1.9369\n",
      "Epoch 5/100, Average Loss: 1.3059\n",
      "Epoch 6/100, Average Loss: 0.8358\n",
      "Epoch 7/100, Average Loss: 0.5560\n",
      "Epoch 8/100, Average Loss: 0.4165\n",
      "Epoch 9/100, Average Loss: 0.3442\n",
      "Epoch 10/100, Average Loss: 0.3007\n",
      "Epoch 11/100, Average Loss: 0.2707\n",
      "Epoch 12/100, Average Loss: 0.2482\n",
      "Epoch 13/100, Average Loss: 0.2305\n",
      "Epoch 14/100, Average Loss: 0.2163\n",
      "Epoch 15/100, Average Loss: 0.2046\n",
      "Epoch 16/100, Average Loss: 0.1948\n",
      "Epoch 17/100, Average Loss: 0.1865\n",
      "Epoch 18/100, Average Loss: 0.1795\n",
      "Epoch 19/100, Average Loss: 0.1733\n",
      "Epoch 20/100, Average Loss: 0.1680\n",
      "Epoch 21/100, Average Loss: 0.1633\n",
      "Epoch 22/100, Average Loss: 0.1591\n",
      "Epoch 23/100, Average Loss: 0.1554\n",
      "Epoch 24/100, Average Loss: 0.1520\n",
      "Epoch 25/100, Average Loss: 0.1489\n",
      "Epoch 26/100, Average Loss: 0.1461\n",
      "Epoch 27/100, Average Loss: 0.1436\n",
      "Epoch 28/100, Average Loss: 0.1412\n",
      "Epoch 29/100, Average Loss: 0.1391\n",
      "Epoch 30/100, Average Loss: 0.1371\n",
      "Epoch 31/100, Average Loss: 0.1352\n",
      "Epoch 32/100, Average Loss: 0.1334\n",
      "Epoch 33/100, Average Loss: 0.1318\n",
      "Epoch 34/100, Average Loss: 0.1302\n",
      "Epoch 35/100, Average Loss: 0.1287\n",
      "Epoch 36/100, Average Loss: 0.1273\n",
      "Epoch 37/100, Average Loss: 0.1260\n",
      "Epoch 38/100, Average Loss: 0.1248\n",
      "Epoch 39/100, Average Loss: 0.1236\n",
      "Epoch 40/100, Average Loss: 0.1224\n",
      "Epoch 41/100, Average Loss: 0.1213\n",
      "Epoch 42/100, Average Loss: 0.1203\n",
      "Epoch 43/100, Average Loss: 0.1193\n",
      "Epoch 44/100, Average Loss: 0.1183\n",
      "Epoch 45/100, Average Loss: 0.1174\n",
      "Epoch 46/100, Average Loss: 0.1165\n",
      "Epoch 47/100, Average Loss: 0.1157\n",
      "Epoch 48/100, Average Loss: 0.1149\n",
      "Epoch 49/100, Average Loss: 0.1141\n",
      "Epoch 50/100, Average Loss: 0.1134\n",
      "Epoch 51/100, Average Loss: 0.1126\n",
      "Epoch 52/100, Average Loss: 0.1119\n",
      "Epoch 53/100, Average Loss: 0.1113\n",
      "Epoch 54/100, Average Loss: 0.1106\n",
      "Epoch 55/100, Average Loss: 0.1100\n",
      "Epoch 56/100, Average Loss: 0.1094\n",
      "Epoch 57/100, Average Loss: 0.1088\n",
      "Epoch 58/100, Average Loss: 0.1083\n",
      "Epoch 59/100, Average Loss: 0.1078\n",
      "Epoch 60/100, Average Loss: 0.1072\n",
      "Epoch 61/100, Average Loss: 0.1068\n",
      "Epoch 62/100, Average Loss: 0.1063\n",
      "Epoch 63/100, Average Loss: 0.1058\n",
      "Epoch 64/100, Average Loss: 0.1054\n",
      "Epoch 65/100, Average Loss: 0.1050\n",
      "Epoch 66/100, Average Loss: 0.1046\n",
      "Epoch 67/100, Average Loss: 0.1042\n",
      "Epoch 68/100, Average Loss: 0.1038\n",
      "Epoch 69/100, Average Loss: 0.1035\n",
      "Epoch 70/100, Average Loss: 0.1031\n",
      "Epoch 71/100, Average Loss: 0.1028\n",
      "Epoch 72/100, Average Loss: 0.1025\n",
      "Epoch 73/100, Average Loss: 0.1022\n",
      "Epoch 74/100, Average Loss: 0.1019\n",
      "Epoch 75/100, Average Loss: 0.1016\n",
      "Epoch 76/100, Average Loss: 0.1013\n",
      "Epoch 77/100, Average Loss: 0.1011\n",
      "Epoch 78/100, Average Loss: 0.1008\n",
      "Epoch 79/100, Average Loss: 0.1006\n",
      "Epoch 80/100, Average Loss: 0.1003\n",
      "Epoch 81/100, Average Loss: 0.1001\n",
      "Epoch 82/100, Average Loss: 0.0999\n",
      "Epoch 83/100, Average Loss: 0.0997\n",
      "Epoch 84/100, Average Loss: 0.0995\n",
      "Epoch 85/100, Average Loss: 0.0992\n",
      "Epoch 86/100, Average Loss: 0.0990\n",
      "Epoch 87/100, Average Loss: 0.0989\n",
      "Epoch 88/100, Average Loss: 0.0987\n",
      "Epoch 89/100, Average Loss: 0.0985\n",
      "Epoch 90/100, Average Loss: 0.0983\n",
      "Epoch 91/100, Average Loss: 0.0981\n",
      "Epoch 92/100, Average Loss: 0.0980\n",
      "Epoch 93/100, Average Loss: 0.0978\n",
      "Epoch 94/100, Average Loss: 0.0976\n",
      "Epoch 95/100, Average Loss: 0.0975\n",
      "Epoch 96/100, Average Loss: 0.0973\n",
      "Epoch 97/100, Average Loss: 0.0972\n",
      "Epoch 98/100, Average Loss: 0.0970\n",
      "Epoch 99/100, Average Loss: 0.0969\n",
      "Epoch 100/100, Average Loss: 0.0967\n",
      "Accuracy on test set: 0.9333\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ]
  }
 ]
}